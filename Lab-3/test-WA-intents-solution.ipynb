{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76a5766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm-watson\n",
      "  Downloading ibm-watson-11.0.0.tar.gz (358 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (2.3.0)\n",
      "Collecting requests<3.0,>=2.0 (from ibm-watson)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (from ibm-watson) (2.9.0.post0)\n",
      "Collecting websocket-client>=1.1.0 (from ibm-watson)\n",
      "  Downloading websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting ibm_cloud_sdk_core==3.*,>=3.3.6 (from ibm-watson)\n",
      "  Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting urllib3<3.0.0,>=2.4.0 (from ibm_cloud_sdk_core==3.*,>=3.3.6->ibm-watson)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting PyJWT<3.0.0,>=2.10.1 (from ibm_cloud_sdk_core==3.*,>=3.3.6->ibm-watson)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (from python_dateutil>=2.5.3->ibm-watson) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0,>=2.0->ibm-watson)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0,>=2.0->ibm-watson)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0,>=2.0->ibm-watson)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ivanp/Downloads/cb-ollama-lines/make_lines/.conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Downloading ibm_cloud_sdk_core-3.24.2-py3-none-any.whl (75 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-macosx_10_9_universal2.whl (206 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Building wheels for collected packages: ibm-watson\n",
      "  Building wheel for ibm-watson (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-watson: filename=ibm_watson-11.0.0-py3-none-any.whl size=361695 sha256=d0e4bb5b2698f2d0ace3fd63f3304115ce061dc7c1a1f991824fc9ddcf2925b8\n",
      "  Stored in directory: /Users/ivanp/Library/Caches/pip/wheels/d0/17/97/8398dbd81b9628280393ba5d78aff126302313435f7325f302\n",
      "Successfully built ibm-watson\n",
      "Installing collected packages: websocket-client, urllib3, PyJWT, idna, charset_normalizer, certifi, requests, ibm_cloud_sdk_core, ibm-watson\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9/9\u001b[0m [ibm-watson]9\u001b[0m [ibm-watson]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PyJWT-2.10.1 certifi-2025.10.5 charset_normalizer-3.4.4 ibm-watson-11.0.0 ibm_cloud_sdk_core-3.24.2 idna-3.11 requests-2.32.5 urllib3-2.5.0 websocket-client-1.9.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install ibm-watson==7.* pandas\n",
    "!pip install ibm-watson pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd5993d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d7e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watson Assistant client initialized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson import AssistantV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "\n",
    "# --- CONFIG ---\n",
    "\n",
    "\n",
    "# Load environment variables from .env if present\n",
    "load_dotenv()\n",
    "\n",
    "# Read from environment (with defaults to empty string)\n",
    "API_KEY = os.getenv(\"WA_API_KEY\", \"\")\n",
    "SERVICE_URL = os.getenv(\"WA_URL\", \"https://api.us-south.assistant.watson.cloud.ibm.com\")\n",
    "WORKSPACE_ID = os.getenv(\"WA_WORKSPACE_ID\", \"\")\n",
    "\n",
    "# --- CONNECT ---\n",
    "authenticator = IAMAuthenticator(API_KEY)\n",
    "assistant = AssistantV1(\n",
    "    version=\"2021-06-14\",\n",
    "    authenticator=authenticator\n",
    ")\n",
    "assistant.set_service_url(SERVICE_URL)\n",
    "\n",
    "print(\"Watson Assistant client initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'flower_recommendations', 'confidence': 0.977379322052002}]\n",
      "['Thank you, .', 'You can never go wrong with a dozen red roses.']\n"
     ]
    }
   ],
   "source": [
    "# --- TEST MESSAGE ---\n",
    "response = assistant.message(\n",
    "    workspace_id=WORKSPACE_ID,\n",
    "    input={\"text\": \"What flowers do you recommend for Valentine's Day?\"}\n",
    ").get_result()\n",
    "\n",
    "print(response[\"intents\"])\n",
    "print(response[\"output\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f418baf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Watson Assistant Evaluation ===\n",
      "Samples: 4\n",
      "Strict Accuracy:        0.00%\n",
      "Alias-Adjusted Accuracy:86.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§© SECTION: Evaluate Watson Assistant intents (Student Exercise)\n",
    "\n",
    "# ðŸ” Alias map (your old names â†’ workspace names shown in your screenshot)\n",
    "INTENT_ALIASES = {\n",
    "    \"recommend_flowers\": \"flower_recommendations\",\n",
    "    \"hours\": \"hours_info\",\n",
    "    \"store_location\": \"location_info\",\n",
    "    # keep if you truly have it in your workspace:\n",
    "    \"availability\": \"availability\",  # remove if not present\n",
    "}\n",
    "\n",
    "# ðŸ“š Test set\n",
    "TEST_ITEMS = [\n",
    "    (\"Which flowers for Valentine's Day?\", \"recommend_flowers\"),\n",
    "    (\"Are you open on Sundays?\", \"hours\"),\n",
    "    (\"Where are your stores?\", \"store_location\"),\n",
    "    (\"Do you have red roses in stock?\", \"availability\"),\n",
    "]\n",
    "\n",
    "# --- CONNECT ---\n",
    "# TODO: â¶ Initialize the Watson Assistant client here using API_KEY, SERVICE_URL, WORKSPACE_ID\n",
    "# authenticator = ...\n",
    "# assistant = ...\n",
    "# assistant.set_service_url(...)\n",
    "\n",
    "# --- DISCOVER INTENTS ---\n",
    "# TODO: â· Retrieve intents from your workspace and print them\n",
    "# workspace_intents = assistant.list_intents(...).get_result()\n",
    "# actual_intent_names = ...\n",
    "# print(actual_intent_names)\n",
    "\n",
    "# --- EVALUATION LOOP ---\n",
    "rows = []\n",
    "\n",
    "# Define helper function for alias matching\n",
    "def is_alias_match(expected, predicted):\n",
    "    \"\"\"Return True if predicted equals expected OR equals alias(expected).\"\"\"\n",
    "    return predicted == expected or predicted == INTENT_ALIASES.get(expected, None)\n",
    "\n",
    "for text, expected in TEST_ITEMS:\n",
    "    # TODO: â¸ Send message to the Assistant API and capture top intent and confidence\n",
    "    # resp = assistant.message(...).get_result()\n",
    "    # top_intent = ...\n",
    "    # conf = ...\n",
    "    \n",
    "    # --- student complete here ---\n",
    "    strict_ok = ___   # True if top_intent == expected\n",
    "    alias_ok  = ___   # True if is_alias_match(expected, top_intent)\n",
    "    \n",
    "    rows.append({\n",
    "        \"utterance\": text,\n",
    "        \"expected_intent\": expected,\n",
    "        \"predicted_intent\": top_intent,\n",
    "        \"confidence\": round(conf, 3),\n",
    "        \"strict_correct\": strict_ok,\n",
    "        \"alias_correct\": alias_ok\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# --- METRICS (students complete this section) ---\n",
    "N = len(df)\n",
    "\n",
    "# TODO: â¹ Compute strict accuracy and alias-adjusted accuracy\n",
    "# strict_acc = ...\n",
    "# alias_acc  = ...\n",
    "\n",
    "print(\"\\n=== Watson Assistant Evaluation ===\")\n",
    "print(f\"Samples: {N}\")\n",
    "print(f\"Strict Accuracy:        {strict_acc:.2%}\")\n",
    "print(f\"Alias-Adjusted Accuracy:{alias_acc:.2%}\\n\")\n",
    "\n",
    "# TODO: âº Compute a simple confusion matrix (optional bonus)\n",
    "# Hint: use pd.crosstab(df[\"expected_intent\"], df[\"predicted_intent\"])\n",
    "# cm = ...\n",
    "# print(cm)\n",
    "\n",
    "# --- Reflection (students discuss in class) ---\n",
    "# âœ… What does the difference between strict and alias accuracy tell you?\n",
    "# âœ… When would alias-adjusted accuracy be a better indicator?\n",
    "# âœ… How could you extend this evaluation to include precision/recall or F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d7cc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Intents in workspace ===\n",
      "['about_you', 'flower_recommendations', 'goodbyes', 'greetings', 'hours_info', 'location_info', 'thank_you']\n",
      "\n",
      "âš ï¸  Warning: Some expected labels (after alias mapping) are not in this workspace:\n",
      "  - expected 'availability' â†’ mapped 'availability'  (NOT FOUND)\n",
      "\n",
      "=== Watson Assistant Classic â€” Flower Shop Evaluation ===\n",
      "Workspace: d1873eca-ba94-4aed-be7b-f8def6f59f5b\n",
      "Samples:   15\n",
      "Strict Accuracy:         0.00%\n",
      "Alias-Adjusted Accuracy: 86.67%\n",
      "\n",
      "                                    utterance   expected_intent       predicted_intent  confidence  strict_correct  alias_correct\n",
      "           Which flowers for Valentine's Day? recommend_flowers flower_recommendations       0.957           False           True\n",
      "                 What flowers do you suggest? recommend_flowers flower_recommendations       1.000           False           True\n",
      "        Flowers suggestions for my girlfriend recommend_flowers flower_recommendations       1.000           False           True\n",
      "               Can you recommend any flowers? recommend_flowers flower_recommendations       1.000           False           True\n",
      "Can you make a recommendation for a Birthday? recommend_flowers flower_recommendations       1.000           False           True\n",
      "                             When do you open             hours             hours_info       1.000           False           True\n",
      "            What are your hours of operation?             hours             hours_info       1.000           False           True\n",
      "                   Are you open on Saturdays?             hours             hours_info       1.000           False           True\n",
      "                     Are you open on Sundays?             hours             hours_info       1.000           False           True\n",
      "                       Where are your stores?    store_location          location_info       1.000           False           True\n",
      "            Where are you physically located?    store_location          location_info       1.000           False           True\n",
      "  what's the address of your Vancouver store?    store_location          location_info       1.000           False           True\n",
      "    what's the address of your Toronto store?    store_location          location_info       1.000           False           True\n",
      "              Do you have red roses in stock?      availability          location_info       0.595           False          False\n",
      "             Are peonies available this week?      availability             hours_info       0.216           False          False\n",
      "\n",
      "=== Confusion Matrix (rows=expected after alias, cols=predicted) ===\n",
      "                        flower_recommendations  hours_info  location_info\n",
      "availability                                 0           1              1\n",
      "flower_recommendations                       5           0              0\n",
      "hours_info                                   0           4              0\n",
      "location_info                                0           0              4\n",
      "\n",
      "Saved detailed results to watson_flower_shop_eval.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# âœ… SOLUTION (with comments): Evaluate Watson Assistant intents\n",
    "\n",
    "# ---- Imports & setup ---------------------------------------------------------\n",
    "# pandas: tabular handling; collections: lightweight counters/CMs\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# dotenv: lets you keep secrets in a local .env during development\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# IBM Watson Assistant (Classic) SDK\n",
    "from ibm_watson import AssistantV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "# ---- Load configuration from environment ------------------------------------\n",
    "# This reads a local .env file if present (safe for local dev / student laptops).\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"WA_API_KEY\", \"\")\n",
    "SERVICE_URL = os.getenv(\"WA_URL\", \"https://api.us-south.assistant.watson.cloud.ibm.com\")\n",
    "WORKSPACE_ID = os.getenv(\"WA_WORKSPACE_ID\", \"\")\n",
    "\n",
    "# Fast fail with a clear error if something is missing\n",
    "assert API_KEY, \"Missing WA_API_KEY (set in .env or export in your shell)\"\n",
    "assert SERVICE_URL, \"Missing WA_URL (set in .env or export in your shell)\"\n",
    "assert WORKSPACE_ID, \"Missing WA_WORKSPACE_ID (set in .env or export in your shell)\"\n",
    "\n",
    "# ---- Alias map & test set ----------------------------------------------------\n",
    "# INTENT_ALIASES lets us tolerate renamed intents (e.g., workspace uses 'flower_recommendations'\n",
    "# while our exercise still expects 'recommend_flowers'). This prevents false negatives.\n",
    "INTENT_ALIASES = {\n",
    "    \"recommend_flowers\": \"flower_recommendations\",\n",
    "    \"hours\": \"hours_info\",\n",
    "    \"store_location\": \"location_info\",\n",
    "    # keep only if it truly exists in your workspace:\n",
    "    \"availability\": \"availability\",\n",
    "}\n",
    "\n",
    "# A compact test set (you can extend it). Each item: (utterance, expected_intent_label)\n",
    "TEST_ITEMS = [\n",
    "    (\"Which flowers for Valentine's Day?\", \"recommend_flowers\"),\n",
    "    (\"What flowers do you suggest?\", \"recommend_flowers\"),\n",
    "    (\"Flowers suggestions for my girlfriend\", \"recommend_flowers\"),\n",
    "    (\"Can you recommend any flowers?\", \"recommend_flowers\"),\n",
    "    (\"Can you make a recommendation for a Birthday?\", \"recommend_flowers\"),\n",
    "\n",
    "    (\"When do you open\", \"hours\"),\n",
    "    (\"What are your hours of operation?\", \"hours\"),\n",
    "    (\"Are you open on Saturdays?\", \"hours\"),\n",
    "    (\"Are you open on Sundays?\", \"hours\"),\n",
    "\n",
    "    (\"Where are your stores?\", \"store_location\"),\n",
    "    (\"Where are you physically located?\", \"store_location\"),\n",
    "    (\"what's the address of your Vancouver store?\", \"store_location\"),\n",
    "    (\"what's the address of your Toronto store?\", \"store_location\"),\n",
    "\n",
    "    (\"Do you have red roses in stock?\", \"availability\"),\n",
    "    (\"Are peonies available this week?\", \"availability\"),\n",
    "]\n",
    "\n",
    "# ---- Connect to Assistant ----------------------------------------------------\n",
    "# Classic IAM auth + service URL. Version is the API date.\n",
    "authenticator = IAMAuthenticator(API_KEY)\n",
    "assistant = AssistantV1(version=\"2021-06-14\", authenticator=authenticator)\n",
    "assistant.set_service_url(SERVICE_URL)\n",
    "\n",
    "# ---- Optional: Inspect workspace intents ------------------------------------\n",
    "# Useful for sanity checks and showing students how to verify labels exist.\n",
    "workspace_intents = assistant.list_intents(\n",
    "    workspace_id=WORKSPACE_ID, export=False\n",
    ").get_result()\n",
    "actual_intent_names = sorted([i[\"intent\"] for i in workspace_intents.get(\"intents\", [])])\n",
    "\n",
    "print(\"\\n=== Intents in workspace ===\")\n",
    "print(actual_intent_names)\n",
    "\n",
    "# Warn students if any expected (after alias mapping) are absent in the workspace.\n",
    "unknown_expected = set()\n",
    "for _, expected in TEST_ITEMS:\n",
    "    target = INTENT_ALIASES.get(expected, expected)\n",
    "    if target not in actual_intent_names:\n",
    "        unknown_expected.add((expected, target))\n",
    "if unknown_expected:\n",
    "    print(\"\\nâš ï¸  Warning: Some expected labels (after alias mapping) are not in this workspace:\")\n",
    "    for old, mapped in sorted(unknown_expected):\n",
    "        print(f\"  - expected '{old}' â†’ mapped '{mapped}'  (NOT FOUND)\")\n",
    "\n",
    "# ---- Evaluation loop ---------------------------------------------------------\n",
    "# We'll collect per-utterance rows and two confusion trackers:\n",
    "#  - 'confusion'       counts after alias mapping (tolerates renames)\n",
    "#  - 'confusion_strict' counts strict expected vs. predicted\n",
    "rows = []\n",
    "confusion = defaultdict(Counter)        # alias-adjusted\n",
    "confusion_strict = defaultdict(Counter) # strict\n",
    "\n",
    "def is_alias_match(expected: str, predicted: str) -> bool:\n",
    "    \"\"\"True if predicted equals expected OR equals alias(expected).\"\"\"\n",
    "    return predicted == expected or predicted == INTENT_ALIASES.get(expected, None)\n",
    "\n",
    "for text, expected in TEST_ITEMS:\n",
    "    try:\n",
    "        # Call the Assistant with the test utterance.\n",
    "        resp = assistant.message(\n",
    "            workspace_id=WORKSPACE_ID,\n",
    "            input={\"text\": text},\n",
    "        ).get_result()\n",
    "\n",
    "        # Extract the top intent and its confidence if available.\n",
    "        intents = resp.get(\"intents\", [])\n",
    "        top_intent = intents[0][\"intent\"] if intents else \"NONE\"\n",
    "        conf = float(intents[0][\"confidence\"]) if intents else 0.0\n",
    "\n",
    "        # strict_ok: requires exact label match\n",
    "        strict_ok = (top_intent == expected)\n",
    "        # alias_ok: allows a renamed label via INTENT_ALIASES\n",
    "        alias_ok  = is_alias_match(expected, top_intent)\n",
    "\n",
    "        # Record one row per utterance for later tabular reporting.\n",
    "        rows.append({\n",
    "            \"utterance\": text,\n",
    "            \"expected_intent\": expected,\n",
    "            \"predicted_intent\": top_intent,\n",
    "            \"confidence\": round(conf, 3),\n",
    "            \"strict_correct\": strict_ok,\n",
    "            \"alias_correct\": alias_ok\n",
    "        })\n",
    "\n",
    "        # Update confusion counts\n",
    "        expected_alias = INTENT_ALIASES.get(expected, expected)\n",
    "        confusion_strict[expected][top_intent] += 1\n",
    "        confusion[expected_alias][top_intent] += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # If something fails (e.g., network), mark as ERROR so students see it in the table.\n",
    "        rows.append({\n",
    "            \"utterance\": text,\n",
    "            \"expected_intent\": expected,\n",
    "            \"predicted_intent\": \"ERROR\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"strict_correct\": False,\n",
    "            \"alias_correct\": False,\n",
    "            \"error\": str(e),\n",
    "        })\n",
    "        expected_alias = INTENT_ALIASES.get(expected, expected)\n",
    "        confusion_strict[expected][\"ERROR\"] += 1\n",
    "        confusion[expected_alias][\"ERROR\"] += 1\n",
    "\n",
    "# Convert list of dicts â†’ DataFrame for easy metrics & printing.\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ---- Metrics -----------------------------------------------------------------\n",
    "N = len(df)\n",
    "\n",
    "# Strict accuracy: fraction of examples where predicted_intent == expected_intent\n",
    "strict_acc = df[\"strict_correct\"].mean() if N else 0.0\n",
    "\n",
    "# Alias-adjusted accuracy: strict OR predicted equals the alias(expected)\n",
    "alias_acc  = df[\"alias_correct\"].mean() if N else 0.0\n",
    "\n",
    "print(\"\\n=== Watson Assistant Classic â€” Flower Shop Evaluation ===\")\n",
    "print(f\"Workspace: {WORKSPACE_ID}\")\n",
    "print(f\"Samples:   {N}\")\n",
    "print(f\"Strict Accuracy:         {strict_acc:.2%}\")\n",
    "print(f\"Alias-Adjusted Accuracy: {alias_acc:.2%}\\n\")\n",
    "\n",
    "# Show a compact per-row report to help students debug predictions and labels.\n",
    "print(\n",
    "    df[[\"utterance\",\"expected_intent\",\"predicted_intent\",\"confidence\",\"strict_correct\",\"alias_correct\"]]\n",
    "    .to_string(index=False)\n",
    ")\n",
    "\n",
    "# ---- Confusion matrix (alias-adjusted) --------------------------------------\n",
    "# Rows: expected AFTER alias mapping; Cols: predicted labels observed.\n",
    "labels_rows = sorted(set(INTENT_ALIASES.get(e, e) for _, e in TEST_ITEMS))\n",
    "labels_cols = sorted(set(df[\"predicted_intent\"]))\n",
    "\n",
    "cm = pd.DataFrame(\n",
    "    [[confusion[r][c] for c in labels_cols] for r in labels_rows],\n",
    "    index=labels_rows, columns=labels_cols\n",
    ")\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (rows=expected after alias, cols=predicted) ===\")\n",
    "print(cm.to_string())\n",
    "\n",
    "# ---- (Optional) Persist raw results for later grading or class discussion ----\n",
    "out_csv = \"watson_flower_shop_eval.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\"\\nSaved detailed results to {out_csv}\")\n",
    "\n",
    "# ---------------------- Teaching Takeaways ------------------------------------\n",
    "# â€¢ If Strict vs Alias-Adjusted are far apart, your workspace labels differ from the rubricâ€”\n",
    "#   fix aliases or rename intents to stabilize evaluation.\n",
    "# â€¢ Use the confusion matrix to find systematic mix-ups (e.g., 'hours' vs 'store_location').\n",
    "# â€¢ Extend this cell by adding precision/recall per intent or macro/micro F1 if desired.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee235f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per-Intent Metrics (alias-adjusted ground truth) ===\n",
      "                        precision  recall     f1  support  tp  fp  fn\n",
      "availability                  0.0     0.0  0.000        2   0   0   2\n",
      "flower_recommendations        1.0     1.0  1.000        5   5   0   0\n",
      "hours_info                    0.8     1.0  0.889        4   4   1   0\n",
      "location_info                 0.8     1.0  0.889        4   4   1   0\n",
      "\n",
      "=== Averages (alias-adjusted) ===\n",
      " average  precision  recall    f1\n",
      "   micro      0.867   0.867 0.867\n",
      "   macro      0.650   0.750 0.694\n",
      "weighted      0.760   0.867 0.807\n"
     ]
    }
   ],
   "source": [
    "# ====================== OPTIONAL: Per-intent Precision / Recall / F1 ======================\n",
    "# Uses ALIAS-ADJUSTED ground truth so evaluation tolerates renamed intents.\n",
    "\n",
    "# 1) Build alias-adjusted ground truth vs predictions\n",
    "df[\"expected_alias\"] = df[\"expected_intent\"].map(lambda e: INTENT_ALIASES.get(e, e))\n",
    "y_true = df[\"expected_alias\"].fillna(\"NONE\")\n",
    "y_pred = df[\"predicted_intent\"].fillna(\"NONE\")\n",
    "\n",
    "labels = sorted(set(y_true) | set(y_pred))\n",
    "\n",
    "# 2) Compute per-label counts: TP, FP, FN\n",
    "per_label = {}\n",
    "total_tp = total_fp = total_fn = 0\n",
    "supports = {}\n",
    "\n",
    "for L in labels:\n",
    "    tp = int(((y_true == L) & (y_pred == L)).sum())\n",
    "    fp = int(((y_true != L) & (y_pred == L)).sum())\n",
    "    fn = int(((y_true == L) & (y_pred != L)).sum())\n",
    "    support = int((y_true == L).sum())\n",
    "    supports[L] = support\n",
    "\n",
    "    # safe divisions\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1   = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
    "\n",
    "    per_label[L] = {\n",
    "        \"precision\": round(prec, 3),\n",
    "        \"recall\":    round(rec, 3),\n",
    "        \"f1\":        round(f1, 3),\n",
    "        \"support\":   support,\n",
    "        \"tp\": tp, \"fp\": fp, \"fn\": fn,\n",
    "    }\n",
    "\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "\n",
    "per_label_df = pd.DataFrame.from_dict(per_label, orient=\"index\")[[\"precision\",\"recall\",\"f1\",\"support\",\"tp\",\"fp\",\"fn\"]]\n",
    "print(\"\\n=== Per-Intent Metrics (alias-adjusted ground truth) ===\")\n",
    "print(per_label_df.to_string())\n",
    "\n",
    "# 3) Micro / Macro / Weighted averages\n",
    "# Micro: pool all decisions across labels\n",
    "micro_prec = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "micro_rec  = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "micro_f1   = (2 * micro_prec * micro_rec / (micro_prec + micro_rec)) if (micro_prec + micro_rec) > 0 else 0.0\n",
    "\n",
    "# Macro: unweighted mean over labels\n",
    "macro_prec = per_label_df[\"precision\"].mean() if not per_label_df.empty else 0.0\n",
    "macro_rec  = per_label_df[\"recall\"].mean()    if not per_label_df.empty else 0.0\n",
    "macro_f1   = per_label_df[\"f1\"].mean()        if not per_label_df.empty else 0.0\n",
    "\n",
    "# Weighted: mean weighted by class support\n",
    "total_support = per_label_df[\"support\"].sum()\n",
    "if total_support > 0:\n",
    "    weighted_prec = float((per_label_df[\"precision\"] * per_label_df[\"support\"]).sum() / total_support)\n",
    "    weighted_rec  = float((per_label_df[\"recall\"]    * per_label_df[\"support\"]).sum() / total_support)\n",
    "    weighted_f1   = float((per_label_df[\"f1\"]        * per_label_df[\"support\"]).sum() / total_support)\n",
    "else:\n",
    "    weighted_prec = weighted_rec = weighted_f1 = 0.0\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    [\n",
    "        [\"micro\",   round(micro_prec,3),   round(micro_rec,3),   round(micro_f1,3)],\n",
    "        [\"macro\",   round(macro_prec,3),   round(macro_rec,3),   round(macro_f1,3)],\n",
    "        [\"weighted\",round(weighted_prec,3),round(weighted_rec,3),round(weighted_f1,3)],\n",
    "    ],\n",
    "    columns=[\"average\", \"precision\", \"recall\", \"f1\"]\n",
    ")\n",
    "print(\"\\n=== Averages (alias-adjusted) ===\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# ---------------- (Optional) STRICT variant for comparison -------------------\n",
    "# Uncomment to compute the same metrics using strict labels (no alias tolerance).\n",
    "# y_true_strict = df[\"expected_intent\"].fillna(\"NONE\")\n",
    "# y_pred_strict = df[\"predicted_intent\"].fillna(\"NONE\")\n",
    "# labels_strict = sorted(set(y_true_strict) | set(y_pred_strict))\n",
    "# \n",
    "# def compute_metrics(y_true, y_pred, labels):\n",
    "#     total_tp = total_fp = total_fn = 0\n",
    "#     rows = []\n",
    "#     for L in labels:\n",
    "#         tp = int(((y_true == L) & (y_pred == L)).sum())\n",
    "#         fp = int(((y_true != L) & (y_pred == L)).sum())\n",
    "#         fn = int(((y_true == L) & (y_pred != L)).sum())\n",
    "#         support = int((y_true == L).sum())\n",
    "#         prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "#         rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "#         f1   = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0.0\n",
    "#         rows.append((L, round(prec,3), round(rec,3), round(f1,3), support))\n",
    "#         total_tp += tp; total_fp += fp; total_fn += fn\n",
    "#     per_label = pd.DataFrame(rows, columns=[\"label\",\"precision\",\"recall\",\"f1\",\"support\"]).set_index(\"label\")\n",
    "#     micro_prec = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "#     micro_rec  = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "#     micro_f1   = (2 * micro_prec * micro_rec / (micro_prec + micro_rec)) if (micro_prec + micro_rec) > 0 else 0.0\n",
    "#     macro_prec = per_label[\"precision\"].mean() if not per_label.empty else 0.0\n",
    "#     macro_rec  = per_label[\"recall\"].mean()    if not per_label.empty else 0.0\n",
    "#     macro_f1   = per_label[\"f1\"].mean()        if not per_label.empty else 0.0\n",
    "#     total_support = per_label[\"support\"].sum()\n",
    "#     if total_support > 0:\n",
    "#         weighted_prec = float((per_label[\"precision\"] * per_label[\"support\"]).sum() / total_support)\n",
    "#         weighted_rec  = float((per_label[\"recall\"]    * per_label[\"support\"]).sum() / total_support)\n",
    "#         weighted_f1   = float((per_label[\"f1\"]        * per_label[\"support\"]).sum() / total_support)\n",
    "#     else:\n",
    "#         weighted_prec = weighted_rec = weighted_f1 = 0.0\n",
    "#     avg = pd.DataFrame(\n",
    "#         [\n",
    "#             [\"micro\",   round(micro_prec,3),   round(micro_rec,3),   round(micro_f1,3)],\n",
    "#             [\"macro\",   round(macro_prec,3),   round(macro_rec,3),   round(macro_f1,3)],\n",
    "#             [\"weighted\",round(weighted_prec,3),round(weighted_rec,3),round(weighted_f1,3)],\n",
    "#         ],\n",
    "#         columns=[\"average\", \"precision\", \"recall\", \"f1\"]\n",
    "#     )\n",
    "#     return per_label, avg\n",
    "# \n",
    "# strict_per_label, strict_avg = compute_metrics(y_true_strict, y_pred_strict, labels_strict)\n",
    "# print(\"\\n=== Per-Intent Metrics (STRICT) ===\")\n",
    "# print(strict_per_label.to_string())\n",
    "# print(\"\\n=== Averages (STRICT) ===\")\n",
    "# print(strict_avg.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7b3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
